{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/nltk/tag/stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n",
      "//anaconda/lib/python3.5/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import lucem_illud #pip install -U git+git://github.com/Computational-Content-Analysis-2018/lucem_illud.git\n",
    "\n",
    "#All these packages need to be installed from pip\n",
    "#For NLP\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np #For arrays\n",
    "import pandas #Gives us DataFrames\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import seaborn #Makes the graphics look nicer\n",
    "\n",
    "#Displays the graphs\n",
    "import graphviz #You also need to install the command line graphviz\n",
    "\n",
    "#These are from the standard library\n",
    "import os.path\n",
    "import zipfile\n",
    "import subprocess\n",
    "import io\n",
    "import tempfile\n",
    "import lucem_illud.stanford as stanford\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">How would you extract relevant information about the Trayvon Martin sentence directly from the dependency parse (above)? Code an example here. (For instance, what compound nouns show up with what verb phrases within the sentence?) How could these approaches inform your research project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 15.613 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [17.2 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0114 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/86/kbyspkys411_n8krrz1xl9cc0000gn/T/tmpb77axqk3\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>elephant</td>\n",
       "      <td>is in</td>\n",
       "      <td>my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant in my pajamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I</td>\n",
       "      <td>saw</td>\n",
       "      <td>elephant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>brown fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>quick fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>fox</td>\n",
       "      <td>jumped over</td>\n",
       "      <td>lazy dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed stimulus efforts in</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent intervie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in recent interview with Wall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in recent interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "      <td>is in</td>\n",
       "      <td>recent interview with Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts in interview with Wall Street...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Christine Lagarde</td>\n",
       "      <td>discussed</td>\n",
       "      <td>short-term stimulus efforts in interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>recent interview</td>\n",
       "      <td>is with</td>\n",
       "      <td>Wall Street Journal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was African American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was American from</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Trayvon Benjamin Martin</td>\n",
       "      <td>was</td>\n",
       "      <td>African American</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    certainty                      subject                           verb  \\\n",
       "0         1.0                     elephant                          is in   \n",
       "1         1.0                            I                            saw   \n",
       "2         1.0                            I                            saw   \n",
       "3         1.0              quick brown fox                    jumped over   \n",
       "4         1.0              quick brown fox                    jumped over   \n",
       "5         1.0                    quick fox                    jumped over   \n",
       "6         1.0                          fox                    jumped over   \n",
       "7         1.0                    brown fox                    jumped over   \n",
       "8         1.0                    brown fox                    jumped over   \n",
       "9         1.0                    quick fox                    jumped over   \n",
       "10        1.0                          fox                    jumped over   \n",
       "11        1.0            Christine Lagarde                      discussed   \n",
       "12        1.0            Christine Lagarde                      discussed   \n",
       "13        1.0            Christine Lagarde                      discussed   \n",
       "14        1.0            Christine Lagarde  discussed stimulus efforts in   \n",
       "15        1.0            Christine Lagarde                      discussed   \n",
       "16        1.0            Christine Lagarde                      discussed   \n",
       "17        1.0            Christine Lagarde                      discussed   \n",
       "18        1.0  short-term stimulus efforts                          is in   \n",
       "19        1.0            Christine Lagarde                      discussed   \n",
       "20        1.0            Christine Lagarde                      discussed   \n",
       "21        1.0            Christine Lagarde                      discussed   \n",
       "22        1.0            Christine Lagarde                      discussed   \n",
       "23        1.0             recent interview                        is with   \n",
       "24        1.0                       Martin                            was   \n",
       "25        1.0      Trayvon Benjamin Martin      was African American from   \n",
       "26        1.0      Trayvon Benjamin Martin              was American from   \n",
       "27        1.0      Trayvon Benjamin Martin                            was   \n",
       "28        1.0      Trayvon Benjamin Martin                            was   \n",
       "\n",
       "                                               object  \n",
       "0                                          my pajamas  \n",
       "1                              elephant in my pajamas  \n",
       "2                                            elephant  \n",
       "3                                            lazy dog  \n",
       "4                                                 dog  \n",
       "5                                                 dog  \n",
       "6                                                 dog  \n",
       "7                                            lazy dog  \n",
       "8                                                 dog  \n",
       "9                                            lazy dog  \n",
       "10                                           lazy dog  \n",
       "11  short-term stimulus efforts in interview with ...  \n",
       "12                      stimulus efforts in interview  \n",
       "13               stimulus efforts in recent interview  \n",
       "14                                             France  \n",
       "15  short-term stimulus efforts in recent intervie...  \n",
       "16  stimulus efforts in recent interview with Wall...  \n",
       "17    short-term stimulus efforts in recent interview  \n",
       "18          recent interview with Wall Street Journal  \n",
       "19  stimulus efforts in interview with Wall Street...  \n",
       "20                                   stimulus efforts  \n",
       "21                        short-term stimulus efforts  \n",
       "22           short-term stimulus efforts in interview  \n",
       "23                                Wall Street Journal  \n",
       "24                                            African  \n",
       "25                                            Florida  \n",
       "26                                            Florida  \n",
       "27                                           American  \n",
       "28                                   African American  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['I saw the elephant in my pajamas.', \n",
    "        'The quick brown fox jumped over the lazy dog.', \n",
    "        'While in France, Christine Lagarde discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.', \n",
    "        'Trayvon Benjamin Martin was an African American from Miami Gardens, Florida, who, at 17 years old, was fatally shot by George Zimmerman, a neighborhood watch volunteer, in Sanford, Florida.', \n",
    "        'Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo']\n",
    "\n",
    "ieDF = stanford.openIE(text)\n",
    "ieDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25    was African American from\n",
       "26            was American from\n",
       "27                          was\n",
       "28                          was\n",
       "Name: verb, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'Trayvon Benjamin Martin']['verb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25             Florida\n",
       "26             Florida\n",
       "27            American\n",
       "28    African American\n",
       "Name: object, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'Trayvon Benjamin Martin']['object']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\"> I may use this method to find the usage of concepts in philosophical work. For instance, the verb and object can give me information about what a concept means in a specific paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">*Exercise 5*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, perform open information extraction on a modest subset of texts relevant to your final project. Analyze the relative attachment of several subjects relative to verbs and objects and visa versa. Describe how you would select among these statements to create a database of high-value statements for your project and then do it by extracting relevant statements into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In reality I had set my heart at that time on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The method of this man is quite contrary to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of them has been provisionally victoriou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is simply the long history of the origin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entertaining, as I do, these thoughts, I am, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Undoubtedly the bad conscience is an illness, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the meaning of ascetic ideals? In arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>And now, after we have caught sight of the _as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>When he has to tackle sufferers of the lower o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  In reality I had set my heart at that time on ...\n",
       "1  The method of this man is quite contrary to th...\n",
       "2  Which of them has been provisionally victoriou...\n",
       "3  This is simply the long history of the origin ...\n",
       "4  Entertaining, as I do, these thoughts, I am, l...\n",
       "5  Undoubtedly the bad conscience is an illness, ...\n",
       "6  What is the meaning of ascetic ideals? In arti...\n",
       "7  And now, after we have caught sight of the _as...\n",
       "8  When he has to tackle sufferers of the lower o..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetDir = 'sentence'\n",
    "platoText = []\n",
    "platoFileName = []\n",
    "\n",
    "for file in (file for file in os.scandir(targetDir) if file.is_file() and not file.name.startswith('.')):\n",
    "    with open(file.path, encoding = 'latin-1') as f:\n",
    "        platoText.append(f.read())\n",
    "    platoFileName.append(file.name)\n",
    "\n",
    "paragraph = pandas.DataFrame({'text' : platoText})\n",
    "remove = np.array([r'\\[\\d+\\]', r'\\(\\d+\\)', '\\n', '\\t', '\\d+', r'\\(\\w+\\)'])\n",
    "for i in range(paragraph.shape[0]):\n",
    "    for j in range(len(remove)):\n",
    "        paragraph[\"text\"].iloc[i] = re.sub(remove[j], ' ', paragraph[\"text\"].iloc[i])\n",
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting OpenIE run\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger ... done [1.2 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model file: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... \n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 99996, Elapsed Time: 13.354 (s)\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [14.8 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator natlog\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator openie\n",
      "[main] INFO edu.stanford.nlp.naturalli.ClauseSplitter - Loading clause splitter from edu/stanford/nlp/models/naturalli/clauseSearcherModel.ser.gz ... done [0.0102 seconds]\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - Processing file: /var/folders/86/kbyspkys411_n8krrz1xl9cc0000gn/T/tmpbr7zkscs\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - All files have been queued; awaiting termination...\n",
      "[main] INFO edu.stanford.nlp.naturalli.OpenIE - DONE processing files. 0 exceptions encountered.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>certainty</th>\n",
       "      <th>subject</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>material</td>\n",
       "      <td>creates concept for</td>\n",
       "      <td>himself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>material</td>\n",
       "      <td>creates</td>\n",
       "      <td>concept of bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>material</td>\n",
       "      <td>then creates concept for</td>\n",
       "      <td>himself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>material</td>\n",
       "      <td>creates concept of bad for</td>\n",
       "      <td>himself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>method</td>\n",
       "      <td>is contrary to</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>method</td>\n",
       "      <td>is contrary to</td>\n",
       "      <td>quite that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>material</td>\n",
       "      <td>creates</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>material</td>\n",
       "      <td>then creates concept of bad for</td>\n",
       "      <td>himself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>material</td>\n",
       "      <td>then creates</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>material</td>\n",
       "      <td>then creates</td>\n",
       "      <td>concept of bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>essential act</td>\n",
       "      <td>is in</td>\n",
       "      <td>conception of slave-morality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>identical contrary</td>\n",
       "      <td>is in</td>\n",
       "      <td>idea good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>question</td>\n",
       "      <td>be</td>\n",
       "      <td>asked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>be</td>\n",
       "      <td>answered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>it</td>\n",
       "      <td>be</td>\n",
       "      <td>answered thus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>reference</td>\n",
       "      <td>is in</td>\n",
       "      <td>their relations other find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>wild student 's prank</td>\n",
       "      <td>had</td>\n",
       "      <td>had played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>wild student</td>\n",
       "      <td>has</td>\n",
       "      <td>prank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>wild student 's prank</td>\n",
       "      <td>had</td>\n",
       "      <td>merely had played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>poets</td>\n",
       "      <td>ample theme</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.460989</td>\n",
       "      <td>they</td>\n",
       "      <td>_</td>\n",
       "      <td>revert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.460188</td>\n",
       "      <td>they</td>\n",
       "      <td>vent with</td>\n",
       "      <td>impunity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>poets</td>\n",
       "      <td>now theme</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>poets</td>\n",
       "      <td>now ample theme</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>student 's prank</td>\n",
       "      <td>had</td>\n",
       "      <td>merely had played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>jubilant monsters</td>\n",
       "      <td>is with</td>\n",
       "      <td>bravado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>student 's prank</td>\n",
       "      <td>had</td>\n",
       "      <td>had played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>poets</td>\n",
       "      <td>theme</td>\n",
       "      <td>sing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>hidden core</td>\n",
       "      <td>needed outlet from</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>core</td>\n",
       "      <td>needed</td>\n",
       "      <td>outlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tools</td>\n",
       "      <td>constitute</td>\n",
       "      <td>more of argument</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>civilisation</td>\n",
       "      <td>tools of are</td>\n",
       "      <td>disgrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tools</td>\n",
       "      <td>constitute</td>\n",
       "      <td>more of argument more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>civilisation</td>\n",
       "      <td>should</td>\n",
       "      <td>should suspected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tools</td>\n",
       "      <td>constitute</td>\n",
       "      <td>more more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tools</td>\n",
       "      <td>constitute</td>\n",
       "      <td>more of argument against civilisation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>one</td>\n",
       "      <td>on</td>\n",
       "      <td>guard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>One</td>\n",
       "      <td>be</td>\n",
       "      <td>may perfectly justified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>One</td>\n",
       "      <td>be</td>\n",
       "      <td>may justified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>consider</td>\n",
       "      <td>inner meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tame man</td>\n",
       "      <td>consider</td>\n",
       "      <td>principle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tame man</td>\n",
       "      <td>consider</td>\n",
       "      <td>inner meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tame man</td>\n",
       "      <td>consider</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>consider</td>\n",
       "      <td>principle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tame man</td>\n",
       "      <td>consider</td>\n",
       "      <td>himself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>consider</td>\n",
       "      <td>man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>consider</td>\n",
       "      <td>meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.009165</td>\n",
       "      <td>he</td>\n",
       "      <td>certain right</td>\n",
       "      <td>consider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tame man</td>\n",
       "      <td>consider</td>\n",
       "      <td>historic principle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>worm man</td>\n",
       "      <td>is in</td>\n",
       "      <td>foreground</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.009165</td>\n",
       "      <td>he</td>\n",
       "      <td>right</td>\n",
       "      <td>consider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.071498</td>\n",
       "      <td>tame man</td>\n",
       "      <td>learnt</td>\n",
       "      <td>consider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>consider</td>\n",
       "      <td>historic principle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>consider</td>\n",
       "      <td>himself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tame man</td>\n",
       "      <td>consider</td>\n",
       "      <td>meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.009165</td>\n",
       "      <td>he</td>\n",
       "      <td>certain right so</td>\n",
       "      <td>consider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>man</td>\n",
       "      <td>consider</td>\n",
       "      <td>goal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.009165</td>\n",
       "      <td>he</td>\n",
       "      <td>right so</td>\n",
       "      <td>consider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.071498</td>\n",
       "      <td>man</td>\n",
       "      <td>learnt</td>\n",
       "      <td>consider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>tame man</td>\n",
       "      <td>consider</td>\n",
       "      <td>goal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     certainty                subject                             verb  \\\n",
       "0     1.000000               material              creates concept for   \n",
       "1     1.000000               material                          creates   \n",
       "2     1.000000               material         then creates concept for   \n",
       "3     1.000000               material       creates concept of bad for   \n",
       "4     1.000000                 method                   is contrary to   \n",
       "5     1.000000                 method                   is contrary to   \n",
       "6     1.000000               material                          creates   \n",
       "7     1.000000               material  then creates concept of bad for   \n",
       "8     1.000000               material                     then creates   \n",
       "9     1.000000               material                     then creates   \n",
       "10    1.000000          essential act                            is in   \n",
       "11    1.000000     identical contrary                            is in   \n",
       "12    1.000000               question                               be   \n",
       "13    1.000000                     it                               be   \n",
       "14    1.000000                     it                               be   \n",
       "15    1.000000              reference                            is in   \n",
       "16    1.000000  wild student 's prank                              had   \n",
       "17    1.000000           wild student                              has   \n",
       "18    1.000000  wild student 's prank                              had   \n",
       "19    1.000000                  poets                      ample theme   \n",
       "20    0.460989                   they                                _   \n",
       "21    0.460188                   they                        vent with   \n",
       "22    1.000000                  poets                        now theme   \n",
       "23    1.000000                  poets                  now ample theme   \n",
       "24    1.000000       student 's prank                              had   \n",
       "25    1.000000      jubilant monsters                          is with   \n",
       "26    1.000000       student 's prank                              had   \n",
       "27    1.000000                  poets                            theme   \n",
       "28    1.000000            hidden core               needed outlet from   \n",
       "29    1.000000                   core                           needed   \n",
       "..         ...                    ...                              ...   \n",
       "112   1.000000                  tools                       constitute   \n",
       "113   1.000000           civilisation                     tools of are   \n",
       "114   1.000000                  tools                       constitute   \n",
       "115   1.000000           civilisation                           should   \n",
       "116   1.000000                  tools                       constitute   \n",
       "117   1.000000                  tools                       constitute   \n",
       "118   1.000000                    one                               on   \n",
       "119   1.000000                    One                               be   \n",
       "120   1.000000                    One                               be   \n",
       "121   1.000000                    man                         consider   \n",
       "122   1.000000               tame man                         consider   \n",
       "123   1.000000               tame man                         consider   \n",
       "124   1.000000               tame man                         consider   \n",
       "125   1.000000                    man                         consider   \n",
       "126   1.000000               tame man                         consider   \n",
       "127   1.000000                    man                         consider   \n",
       "128   1.000000                    man                         consider   \n",
       "129   0.009165                     he                    certain right   \n",
       "130   1.000000               tame man                         consider   \n",
       "131   1.000000               worm man                            is in   \n",
       "132   0.009165                     he                            right   \n",
       "133   0.071498               tame man                           learnt   \n",
       "134   1.000000                    man                         consider   \n",
       "135   1.000000                    man                         consider   \n",
       "136   1.000000               tame man                         consider   \n",
       "137   0.009165                     he                 certain right so   \n",
       "138   1.000000                    man                         consider   \n",
       "139   0.009165                     he                         right so   \n",
       "140   0.071498                    man                           learnt   \n",
       "141   1.000000               tame man                         consider   \n",
       "\n",
       "                                    object  \n",
       "0                                  himself  \n",
       "1                           concept of bad  \n",
       "2                                  himself  \n",
       "3                                  himself  \n",
       "4                                     that  \n",
       "5                               quite that  \n",
       "6                                  concept  \n",
       "7                                  himself  \n",
       "8                                  concept  \n",
       "9                           concept of bad  \n",
       "10            conception of slave-morality  \n",
       "11                               idea good  \n",
       "12                                   asked  \n",
       "13                                answered  \n",
       "14                           answered thus  \n",
       "15              their relations other find  \n",
       "16                              had played  \n",
       "17                                   prank  \n",
       "18                       merely had played  \n",
       "19                                    sing  \n",
       "20                                  revert  \n",
       "21                                impunity  \n",
       "22                                    sing  \n",
       "23                                    sing  \n",
       "24                       merely had played  \n",
       "25                                 bravado  \n",
       "26                              had played  \n",
       "27                                    sing  \n",
       "28                                    time  \n",
       "29                                  outlet  \n",
       "..                                     ...  \n",
       "112                       more of argument  \n",
       "113                               disgrace  \n",
       "114                  more of argument more  \n",
       "115                       should suspected  \n",
       "116                              more more  \n",
       "117  more of argument against civilisation  \n",
       "118                                  guard  \n",
       "119                may perfectly justified  \n",
       "120                          may justified  \n",
       "121                          inner meaning  \n",
       "122                              principle  \n",
       "123                          inner meaning  \n",
       "124                                    man  \n",
       "125                              principle  \n",
       "126                                himself  \n",
       "127                                    man  \n",
       "128                                meaning  \n",
       "129                               consider  \n",
       "130                     historic principle  \n",
       "131                             foreground  \n",
       "132                               consider  \n",
       "133                               consider  \n",
       "134                     historic principle  \n",
       "135                                himself  \n",
       "136                                meaning  \n",
       "137                               consider  \n",
       "138                                   goal  \n",
       "139                               consider  \n",
       "140                               consider  \n",
       "141                                   goal  \n",
       "\n",
       "[142 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF = stanford.openIE(paragraph['text'][1])\n",
    "ieDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Our audacity             12\n",
       "he                       10\n",
       "tools                     8\n",
       "man                       8\n",
       "it                        8\n",
       "material                  8\n",
       "tame man                  8\n",
       "Europe                    7\n",
       "I                         6\n",
       "Pericles                  6\n",
       "truth                     5\n",
       "aristocratic races        4\n",
       "civilisation              4\n",
       "races                     4\n",
       "poets                     4\n",
       "nay                       4\n",
       "core                      3\n",
       "hidden core               3\n",
       "method                    2\n",
       "idea                      2\n",
       "pride                     2\n",
       "One                       2\n",
       "wild student 's prank     2\n",
       "they                      2\n",
       "student 's prank          2\n",
       "nonchalance               2\n",
       "reference                 1\n",
       "worm man                  1\n",
       "question                  1\n",
       "wild student              1\n",
       "identical contrary        1\n",
       "bearers                   1\n",
       "vindictive instincts      1\n",
       "essential act             1\n",
       "one                       1\n",
       "pre-Aryan population      1\n",
       "jubilant monsters         1\n",
       "world                     1\n",
       "everything                1\n",
       "same time awful           1\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animal                 2\n",
       "prey                   1\n",
       "domesticated animal    1\n",
       "tame animal            1\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'truth']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "consider    7\n",
       "learnt      1\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'tame man']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inner meaning         1\n",
       "himself               1\n",
       "man                   1\n",
       "principle             1\n",
       "goal                  1\n",
       "consider              1\n",
       "historic principle    1\n",
       "meaning               1\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'tame man']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "their ideals        2\n",
       "degraded            1\n",
       "finally degraded    1\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'races']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "more of argument against civilisation more    1\n",
       "more of argument                              1\n",
       "more of argument more                         1\n",
       "more more                                     1\n",
       "disgrace                                      1\n",
       "more of argument against civilisation         1\n",
       "more                                          1\n",
       "humanity                                      1\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'tools']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constitute         6\n",
       "are                1\n",
       "are disgrace to    1\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'tools']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sets ?? in    2\n",
       "says in       2\n",
       "sets          1\n",
       "says to       1\n",
       "Name: verb, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'Pericles']['verb'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "special relief                1\n",
       "his Athenians                 1\n",
       "funeral oration               1\n",
       "celebrated funeral oration    1\n",
       "relief                        1\n",
       "??                            1\n",
       "Name: object, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDF[ieDF['subject'] == 'Pericles']['object'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<span style=\"color:blue\"> It's interesting that in Nietzsche's work the concept truth is related to tamed/domestic animals. It might implicate his opinion on truth: there is not truth, but discipline."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
